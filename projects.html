<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Valeria Bodishtianu</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        /* Collapsible style */
        .collapsible {
            cursor: pointer;
            padding: 10px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 16px;
        }
        
        .active, .collapsible:hover {
            background-color: #f4f4f4;
        }
        
        .content {
            padding: 0 18px;
            display: none;
            overflow: hidden;
            background-color: #f9f9f9;
        }
    </style>
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="projects.html">Projects</a>
            <a href="teaching.html">Teaching</a>
            <a href="contact.html">Contact</a>
        </nav>
    </header>
    
    <section id="projects">
        <h2>Working Papers</h2>
        
        <h3><a href="https://arxiv.org/abs/2406.03299" target="_blank">Polarization under Biased Argument Sharing</a> </h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> Polarization of opinions has been a widely studied phenomena for decades. Multiple models suggest the degree of polarization with little consensus on which elements are crucial to the study. Homophily has largely been considered to be the key parameter; however, empirically obtained levels of homophily in society aren’t enough to explain the severity of polarization we observe. In this paper we attempt to cross that distance by modifying the argument communication model to include biased argument sharing - justified by people’s tendency to diverge from optimal signals that could misidentify them as belonging to dissimilar groups. We find that our model shows consistently higher levels of polarization for any given value of homophily, which means that our results could be closer to empirically obtained values. Results are more robust for societies with higher numbers of agents, making our model suitable for researching polarization on online social networks. We also find that dividing populations into groups not inherently based on their opinion doesn’t affect polarization. Dividing population lowers polarization if the biased argument sharing is based on the group membership rather than agent’s opinion.</p>
        </div>

        <h3><a href="https://arxiv.org/abs/2406.03299" target="_blank">Information Aggregation in Presence of Media on a Network with Experts</a> </h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> The digital age has transformed the process of information spread and aggregation, giving
rise to social media platforms that challenge traditional news outlets' dominance in shaping
public opinion. This shift is accompanied by individual agents becoming content producers
in addition to consuming, thereby creating a more direct form of communication between
various parts of the social network. Historical reliance on traditional media has shifted
towards a more fragmented information landscape, where social media plays a significant
role in the dissemination and consumption of news. This transition raises important
questions about the nature of information aggregation in social networks and its capacity to
counteract biased narratives presented by mainstream media outlets.
In this paper I present a model of a communication system on a network between
inherently truth-seeking individuals. At the heart of my model is the role of knowledgeable agents (experts or witnesses), who serve as anchors of true information
within the network, countering the influence of slanted media signals. The central research
questions we address include how the distribution of knowledgeable agents impacts
information diffusion and the effectiveness of optimal placement strategies compared to
other policies aimed at reducing media bias.</p>
        </div>

        <h3><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4747531" target="_blank">When Do People Fact Check? An Experimental Study</a> (with Dongfang Gaozhao and Pengfei Zhang)</h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> This paper investigates the causes and consequences of fact-checking. Through an online experiment, we examined three competing theories of fact-checking behavior—Value of Information, Limited Attention, and Motivated Reasoning—under varying conditions of incentives and prior awareness.</p>
        </div>

        <h3><a href="https://arxiv.org/abs/2406.03299" target="_blank">The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games</a> (with ...)</h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> This paper presents a novel framework to study the decision-making of large language models (LLMs) under emotional states, demonstrating how emotions can alter the strategies employed by LLMs in cooperative and bargaining scenarios.</p>
        </div>
        
        <h2>Publications</h2>
        
        <h3><a href="https://neurips.cc/" target="_blank">EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas</a> (in NeurIPS 2024)</h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> This study explores the alignment of LLMs with human ethical standards in strategic and ethical dilemmas, emphasizing the effect of emotions on decision-making and cooperation in game-theoretic scenarios.</p>
        </div>

        <h3><a href="https://aaai.org/papers/632-flairs-2017-15469/" target="_blank">Logic of Existentialism in Fiction</a> (with Ilya Makarov, in FLAIRS 2017)</h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> This paper addresses the problem of fictional objects in logic and provides a framework for evaluating statements involving fictional entities in terms of existence and quantification across possible worlds.</p>
        </div>

        <h3><a href="https://aaai.org/papers/412-flairs-2017-15463/" target="_blank">Adapting First-Person Shooter Video Game for Playing with Virtual Reality Headsets</a> (with Ilya Makarov, Oleg Konoplia, Pavel Polyakov, Maxim Martynov, Peter Zyuzin, Olga Gerasimova, in FLAIRS 2017)</h3>
        <button type="button" class="collapsible">▼ Abstract</button>
        <div class="content">
            <p><strong>Abstract:</strong> This paper explores advancements in combining virtual reality (VR) technologies with adaptive BOT behavior in first-person shooter games to enhance the realism and immersion of VR gameplay.</p>
        </div>
    </section>
    
    <footer>
        <p>&copy; 2024 Valeria Bodishtianu</p>
    </footer>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }
    </script>
</body>
</html>
